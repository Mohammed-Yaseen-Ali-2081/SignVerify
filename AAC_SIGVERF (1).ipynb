{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ANACONDA PYTHON\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orginal_Signatures = \"F:\\\\Aac dataset\\\\Dataset\\\\real/\"\n",
    "Fake_Signatures = \"F:\\\\Aac dataset\\\\Dataset\\\\forged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColorToGray(img):\n",
    "    Grayimage = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            Grayimage[i][j] = np.average(img[i][j])\n",
    "    return Grayimage\n",
    "def GrayToBinary(img):\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)\n",
    "    ThresholdFreq = threshold_otsu(img)\n",
    "    BinaryImg = img > ThresholdFreq\n",
    "    BinaryImg = np.logical_not(BinaryImg)\n",
    "    return BinaryImg\n",
    "def PreProccesing(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    Grey = ColorToGray(img)\n",
    "    if display:\n",
    "        plt.imshow(Grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    BinaryImg = GrayToBinary(Grey)\n",
    "    if display:\n",
    "        plt.imshow(BinaryImg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(BinaryImg==1)\n",
    "    SignatureImage = BinaryImg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(SignatureImage, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return SignatureImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculating_Ratio(img):\n",
    "    pixels = 0\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[0])):\n",
    "            if img[i][j]==True:\n",
    "                pixels += 1\n",
    "    total_pixels = img.shape[0] * img.shape[1]\n",
    "    return pixels/total_pixels\n",
    "def Calculating_EccentricityAndSolidity(img):\n",
    "    region = regionprops(img.astype(\"int8\"))\n",
    "    return region[0].eccentricity, region[0].solidity\n",
    "def Calculating_SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)\n",
    "    y = range(h)\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)\n",
    "def Calculating_Centroid(img):\n",
    "    NumberOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[0])):\n",
    "            if img[i][j]==True:\n",
    "                b = np.array([i,j])\n",
    "                a = np.add(a,b)\n",
    "                NumberOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/NumberOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]\n",
    "def Feature_Extraction(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = PreProccesing(path, display=display)\n",
    "    ratio = Calculating_Ratio(img)\n",
    "    centroid = Calculating_Centroid(img)\n",
    "    eccentricity, solidity = Calculating_EccentricityAndSolidity(img)\n",
    "    skewness, kurtosis = Calculating_SkewKurtosis(img)\n",
    "    feature_tuple = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    features = (feature_tuple[0], feature_tuple[1][0], feature_tuple[1][1], feature_tuple[2], feature_tuple[3], feature_tuple[4][0], feature_tuple[4][1], feature_tuple[5][0], feature_tuple[5][1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Manipulation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCSV():\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\Features')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\Features')\n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\Features/Training')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\Features/Testing')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "    for person in range(1,13):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "        print('Saving features for person id-',per)\n",
    "        \n",
    "        with open('F:\\\\Aac dataset\\\\Dataset\\\\Features\\\\Training/training_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(Orginal_Signatures, per+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(Fake_Signatures, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')\n",
    "        \n",
    "        with open('F:\\\\Aac dataset\\\\Dataset\\\\Features\\\\Testing/testing_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            for i in range(3, 5):\n",
    "                source = os.path.join(Orginal_Signatures, per+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(3,5):\n",
    "                source = os.path.join(Fake_Signatures, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA PYTHON\\lib\\site-packages\\skimage\\measure\\_regionprops.py:250: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See https://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n",
      "D:\\ANACONDA PYTHON\\lib\\site-packages\\skimage\\measure\\_regionprops.py:260: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See https://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 002\n",
      "Saving features for person id- 003\n",
      "Saving features for person id- 004\n",
      "Saving features for person id- 005\n",
      "Saving features for person id- 006\n",
      "Saving features for person id- 007\n",
      "Saving features for person id- 008\n",
      "Saving features for person id- 009\n",
      "Saving features for person id- 010\n",
      "Saving features for person id- 011\n",
      "Saving features for person id- 012\n"
     ]
    }
   ],
   "source": [
    "makeCSV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox \n",
    "from PIL import ImageTk, Image\n",
    "def browse():\n",
    "\tfilename = filedialog.askopenfilename(filetypes = ((\"All Files\",\"*.*\"),(\"File\",\"*.py\")))\n",
    "\tpath.config(text = filename)\n",
    "\ta = filename\n",
    "\tglobal file \n",
    "\tfile = a\n",
    "def display():\n",
    "    image=Image.open(file+'')\n",
    "    reimage=image.resize((250,250))\n",
    "    my_img = ImageTk.PhotoImage(reimage)\n",
    "    my_label = Label(win,bg=\"black\",image=my_img)\n",
    "    my_label.place(x=500,y=100)\n",
    "    my_label.config(image=file)\n",
    "def sequence(*functions):\n",
    "    def func(*args, **kwargs):\n",
    "        return_value = None\n",
    "        for function in functions:\n",
    "            return_value = function(*args, **kwargs)\n",
    "        return return_value\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ANACONDA PYTHON\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-32-4190f1656d45>\", line 24, in func\n",
      "    return_value = function(*args, **kwargs)\n",
      "  File \"<ipython-input-32-4190f1656d45>\", line 19, in display\n",
      "    my_label.config(image=file)\n",
      "  File \"D:\\ANACONDA PYTHON\\lib\\tkinter\\__init__.py\", line 1485, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "  File \"D:\\ANACONDA PYTHON\\lib\\tkinter\\__init__.py\", line 1476, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: image \"F:/Aac dataset/Dataset/real/002002_000.png\" doesn't exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def WritingFeatures(path):\n",
    "    ExtractedFeatures = Feature_Extraction(path)\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures')\n",
    "    with open('F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, ExtractedFeatures))+'\\n')\n",
    "\n",
    "def readCSV(train_path, test_path, type2=False):\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.np_utils.to_categorical(correct,2) \n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = keras.utils.np_utils.to_categorical(correct,2) \n",
    "    if not(type2):\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n",
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "display_step = 1\n",
    "\n",
    "n_hidden_1 = 7 \n",
    "n_hidden_2 = 10\n",
    "n_hidden_3 = 30 \n",
    "n_classes = 2 \n",
    "\n",
    "\n",
    "X = tf.compat.v1.placeholder(dtype = tf.float32 ,shape= [None, n_input])\n",
    "Y = tf.compat.v1.placeholder(dtype = tf.float32 ,shape= [None, n_classes])\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=3)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], seed=4))\n",
    "}\n",
    "\n",
    "\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "pred = tf.nn.softmax(logits) \n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(training_epochs):\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            if cost<0.0001:\n",
    "                break\n",
    "        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "        if type2 is False:\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
    "            return accuracy1, accuracy2\n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                MsgBox = tk.messagebox.showinfo('Congratulations','Genuine Image')\n",
    "                                                               #F:\\Aac dataset\\Dataset\\real\\001001_002.png\n",
    "            else:                                              #F:\\Aac dataset\\Dataset\\forged\\021001_002.png\n",
    "                MsgBox = tk.messagebox.showwarning ('Beware','Forged Image')\n",
    "                \n",
    "def abc():\n",
    "    n_input = 9\n",
    "    train_person_id = Fname.get()\n",
    "    test_image_path = file\n",
    "    train_path = 'F:\\\\Aac dataset\\\\Dataset\\\\Features\\\\Training/training_'+train_person_id+'.csv'\n",
    "    WritingFeatures(test_image_path)\n",
    "    test_path = 'F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures/testcsv.csv'\n",
    "    evaluate(train_path, test_path, type2=True)\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"1000x700\")\n",
    "win.title(\"Signature Verification\")\n",
    "title = Label(win,text=\"Signature Verification :\",bg=\"gray\",width=\"300\",height=\"2\",fg=\"White\",font = (\"Calibri 20 bold italic underline\")).pack()\n",
    "path = Label(win,font = (\"Verdana 8\"))\n",
    "path.place(x=140,y=150)\n",
    "Fname = Label(win, text=\"Enter Person ID : \",font = (\"Verdana 12\")).place(x=12,y=100)\n",
    "Fname = StringVar()\n",
    "entry_Fname = Entry(win,textvariable = Fname,width=30)\n",
    "entry_Fname.place(x=180,y=100)\n",
    "upload = Button(win, text=\"Load\", width=\"12\",height=\"1\",activebackground=\"blue\", bg=\"Pink\",font = (\"Calibri 12 \"),command = sequence(browse,display)).place(x=20, y=150)\n",
    "submit = Button(win, text=\"Test\", width=\"12\",height=\"1\",activebackground=\"violet\", bg=\"Pink\",command = abc,font = (\"Calibri 12 \")).place(x=420, y=420)\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
